{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Assignment_4.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1hzt6hkMgfuG","colab_type":"text"},"source":["# Assignment 4 CS 5316 Natural Language Processing"]},{"cell_type":"code","metadata":{"id":"TBV0p-4TgfuI","colab_type":"code","outputId":"3be76ca0-adf7-4a38-b5c2-189d4cd1f879","executionInfo":{"status":"ok","timestamp":1589134634482,"user_tz":-300,"elapsed":3310,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["%matplotlib inline\n","import numpy as np\n","from IPython.display import Image\n","# Get the interactive Tools for Matplotlib\n","import matplotlib.pyplot as plt\n","plt.style.use('ggplot')\n","from sklearn.decomposition import PCA\n","from gensim.test.utils import datapath, get_tmpfile\n","from gensim.models import KeyedVectors\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.utils.extmath import randomized_svd\n","from nltk import ngrams\n","import pandas as pd\n","import seaborn as sn\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Activation, RepeatVector,Flatten, TimeDistributed, Input,Bidirectional,LocallyConnected1D,Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n","from tensorflow.keras.layers import Embedding, LSTM ,Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import optimizers\n","# from tensorflow.keras.utils.vis_utils import plot_model\n","from tensorflow.keras.utils import to_categorical\n","# import tensorflow.keras.utils.to_categorical as to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","import matplotlib.pyplot as plt\n","import matplotlib.mlab as mlab\n","from sklearn.model_selection import train_test_split as splitter\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n","from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n","import math\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sn\n","from sklearn.metrics import classification_report\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BaQweu_lgfuN","colab_type":"text"},"source":["# Final Assignment\n","This is going to be the final assignment for deep learning. Here is a very good visual for what you will be doing with\n","<a href=\"https://ibb.co/mh9Ks0j\">deep learning.</a> Lets get started......."]},{"cell_type":"markdown","metadata":{"id":"wcNVOT32gfuN","colab_type":"text"},"source":["# TASK 1 Paraphrase Detection\n","For this task we will be using the [ Microsoft Research Paraphrase Corpus ](https://www.microsoft.com/en-us/download/details.aspx?id=52398). The corpus consist of sentence pairs with 1 or 0 labels which identify if the sentences are paraphrase or not respectively.\n","<br>\n","To perform this task we will be using recurrent neural network for this task specifically the [LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/). RNN can be architected in multiple ways. Some of the possible ways are as follows:\n","<img src=\"archetecturernn.png\">\n","The box in the bottom is the input, followed by the hidden layer (as the middle box), and the box on top is the output layer. The one-to-one architecture is the typical neural network (<i>vanila/Feed Forward</i>) with a hidden layer between the input and the output layer. Example uses of the above archetecture are as follows:\n","<ul>\n","    <li>One-to-many: input is an image and outputs are image captions</li>\n","    <li>Many-to-one: input is a movie's review <i>multiple words in input</i> and output is sentiment associated with the review <i>(we will be using a similar archetecture for our purpose)</i></li>\n","    <li>Many-to-many: machine translation of a sentence in one language to a sentence in another language, POS tagging etc</li>\n","</ul>\n","<br>\n","For this task we will also be using pre-trained word embeddings specificallly <a href=\"https://nlp.stanford.edu/projects/glove/\">(GloVe Embeddings)</a>. Please download the paraphrase <a href=\"https://www.microsoft.com/en-us/download/details.aspx?id=52398\">dataset</a> and glove.6B.zip from <a href=\"https://nlp.stanford.edu/projects/glove/\">here</a>."]},{"cell_type":"markdown","metadata":{"id":"DjTctIsvgfuO","colab_type":"text"},"source":["For this task you are required to implement the following archetecture, please use [keras functional API](https://www.tensorflow.org/guide/keras/functional) :\n","<img src=\"paraphrase.png\">\n","If <a href=\"https://ibb.co/RSSjRM0\">this</a> is you reaction after seeing the model archetecture dont worry we'll explain.\n","The model works as follows, there will be two inputs layers, one for each sentence followed by <b>shared</b> embedding layer which feed thier outputs to the shared LSTM, <b>take the final hidden state output</b> of both LSTM's and concatenate them. Finally feed the concatenated vector to a softmax output layer for classification.\n","<br>\n","<i>(The reason for using one shared embedding and LSTM layer so that the model learns sentence representation for all sentence pairs(x,x') in the dataset. If we were using two seperate LSTMS for x and x' we would need to double the dataset by having both (x,x') and (x',x) pairs so that both LSTM's see the entire train data distribution)</i>\n","The purpose for each layer in the model is as follows:\n","<ul>\n","    <li>Input takes the input sequences and feeds it to the next(you will need to specify the maximum size of a sentence as a parameter of this layer)</li>\n","    <li>Embedding layer, this layer takes the sequence input then for each word in the sequence generates a fixed size vector <i>(word embedding)</i>, this layer can be trained from scratch or can be configured to use pretrained embeddings with or without fine tuning. </li>\n","    <li>LSTM process the embedding vector sequences and at each step generates a hidden state vector(h)and cell memory vector(C)(<i>see diagram</i>), the keras LSTM layer returns three outputs (1) All the hidden states,(2) The final hidden state and (3) The final cell memory state<img src=\"lstm.png\"></li>\n","    <li>The concatenation layer combines multple vectors into a single vector</li>\n","    <li>Finally the output layer predicts if sentence pairs were paraphrase or not</li>\n","</ul>\n","<b>Please refer to the TF-keras documentation for all the layers <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers\">here</a></b>\n","<br><br><br>\n","Now that you understand the theoritical foundation for our approach lets move onto practical implementation.<br>\n","<h3>Data Preperation</h3>\n","\n","<ul>\n","    <li> First we need to preprocess the data, convert the data to lower casing. Any other preprocessing procedures are optional but keep in mind that this will affect the performance of your model.</li>\n","    <li> To make training faster we will fix the maximum sequence length to 20 truncate the longer sequences.</li>\n","    <li> Split the data into test, train and validation in the ratio 20,70,10. Use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">scikit_test_train_split</a> <br><i><b>Hint:</b> use the splitter twice to get desired data splits.</i></li>\n","    <li> Next we need the vocabulary, vocabulary size and to convert sentences to numeric sequences by representing each word with a numeric value which will make our implementation easier later on, use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\">Tokenizer</a> from keras. <br><i>(Fit the tokenizer on train data and use the same tokenizer to convert train,test and validation data to numeric sequences)</i> </li>\n","    <li>  Use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\"> pad sequences</a> to add post padding to all sentences that are shorter than maximum sequence length\n","        <i>(<b>extra info</b>: fit_on_text reserves value/index 0 for padding and assigns numeric value to words starting from index 1)</i></li>\n","</ul>\n","<h3>Loading embeddings</h3>\n","<ul>\n","    <li> To use pretrained embeddings in tf keras embedding layer requires a dictionary, we need to create a dictionary whose keys will be numeric word representations and values will be the embedding vectors.</li>\n","    <li> First step is to load the word embedding pairs from the glove file into a dictionary.</li>\n","    <li> Next we will create a dictionary for our dataset's vocabulary. Copy all the word embeddings for words that are in our vocabulary and in the glove dictionary, if a word exists in our vocabulary but does not exist in glove dictionary create a zero vector of embedding dimension size and add it to the dictionary.</li>\n","</ul>\n","<h3>Create Model</h3>\n","<ul>\n","    <li> Create the model using <a href\"https://www.tensorflow.org/guide/keras/functional\">functional API</a></li>\n","    <li> Hints: The emebedding layer has a parameter that allows you to use pretrained embeddings, for shared layers read the section of shared layer weights in function API docs</li>"]},{"cell_type":"code","metadata":{"id":"aSlJoDACgfuP","colab_type":"code","outputId":"c7224cfb-a244-4267-d0c4-d904aff59d84","executionInfo":{"status":"ok","timestamp":1589132227830,"user_tz":-300,"elapsed":2631,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["def loadData():\n","    \"\"\"\n","    Return preprocessed data\n","    \n","    Returns: X and Y where X is pair of sentence (x,x') and y is the label 0 or 1\n","    \"\"\"\n","    pairs=[]\n","    data=pd.read_table(\"/content/drive/My Drive/Colab Notebooks/Assignment4/msr_paraphrase_train.txt\",error_bad_lines=False)\n","    X1=data['#1 String'].str.lower()\n","    X2=data['#2 String'].str.lower()\n","    labels=data['Quality']\n","    X1=list(X1)\n","    X2=list(X2)\n","    labels=list(labels)\n","    \n","    \n","    \n","    return X1,X2,labels\n","\n","X1,X2,labels=loadData()\n","\n","\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["b'Skipping line 102: expected 5 fields, saw 6\\nSkipping line 656: expected 5 fields, saw 6\\nSkipping line 867: expected 5 fields, saw 6\\nSkipping line 880: expected 5 fields, saw 6\\nSkipping line 980: expected 5 fields, saw 6\\nSkipping line 1439: expected 5 fields, saw 6\\nSkipping line 1473: expected 5 fields, saw 6\\nSkipping line 1822: expected 5 fields, saw 6\\nSkipping line 1952: expected 5 fields, saw 6\\nSkipping line 2009: expected 5 fields, saw 6\\nSkipping line 2230: expected 5 fields, saw 6\\nSkipping line 2506: expected 5 fields, saw 6\\nSkipping line 2523: expected 5 fields, saw 6\\nSkipping line 2809: expected 5 fields, saw 6\\nSkipping line 2887: expected 5 fields, saw 6\\nSkipping line 2920: expected 5 fields, saw 6\\nSkipping line 2944: expected 5 fields, saw 6\\nSkipping line 3241: expected 5 fields, saw 6\\nSkipping line 3358: expected 5 fields, saw 6\\nSkipping line 3459: expected 5 fields, saw 6\\nSkipping line 3491: expected 5 fields, saw 6\\nSkipping line 3643: expected 5 fields, saw 6\\nSkipping line 3696: expected 5 fields, saw 6\\nSkipping line 3955: expected 5 fields, saw 6\\n'\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hFuhoAbsgfuS","colab_type":"code","colab":{}},"source":["def preprocessing(data):\n","    \"\"\"\n","    Return preprocessed data\n","\n","    Args:\n","        data : sentence pairs\n","    \n","    Returns: preprocessed_data\n","    preprocessed_data : preprocessed dataset \n","    \"\"\"\n","    #keeping alphabets and numbers only \n","    for i in range(0,len(data)):\n","      data[i]=\" \".join((re.findall('[a-z0-9]+',str(data[i]))))\n","    \n","    #removing stop words and len(w) == 1\n","    stop_w=set(stopwords.words('english'))\n","    for i in range(0,len(data)):\n","      tokenized=data[i].split(\" \")\n","      filtered=[k for k in tokenized if k not in stop_w and len(k) > 1 ]\n","      data[i]=\" \".join(filtered)\n","\n","    #Truncating\n","    for i in range(0,len(data)):\n","      tokenized=data[i].split(\" \")\n","      if len(tokenized) > 20:\n","        data[i]=\" \".join(tokenized[:20])\n","\n","    return data\n","X1=preprocessing(X1)\n","X2=preprocessing(X2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7017xuzN2qe","colab_type":"code","colab":{}},"source":["def makepairs(X1,X2):\n","  pairs=[]\n","  for i in range(0,len(X1)):\n","    pairs.append((X1[i],X2[i]))\n","  return pairs\n","data = makepairs(X1,X2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mpLBIbEGgfuV","colab_type":"text"},"source":["### Test train split\n","Use test train split from sklearn.\n"]},{"cell_type":"code","metadata":{"id":"oauwq3UegfuW","colab_type":"code","colab":{}},"source":["def testTrainSplit(data_X,data_Y):\n","    \"\"\"\n","    Return test train data\n","\n","    Args:\n","        data_X : sentence pairs\n","        data_Y: labels\n","        \n","    Returns: test train and validation split data \n","    \"\"\"\n","    train_data,valid_data,train_labels,valid_labels=splitter(data_X,data_Y,train_size=0.9,test_size=0.1,shuffle=True)\n","    train_data,test_data,train_labels,test_labels=splitter(train_data,train_labels,train_size=0.8,test_size=0.2,shuffle=True)\n","\n","    return train_data,train_labels,test_data,test_labels,valid_data,valid_labels\n","\n","train_data,train_labels,test_data,test_labels,valid_data,valid_labels=testTrainSplit(data,labels)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h4OyW3_dgfuZ","colab_type":"text"},"source":["Implement the step regarding keras Tokenizer in the cell below.<br>\n","<i> Keep in mind that each example is a pair/tupple of sentence(x,x'), combine them into a single sentence so that your data is a list of sentences before calling fit on text(Tokenizer). There is out of vocabulary option in tokenizer check that out aswell.</i>"]},{"cell_type":"code","metadata":{"id":"NdAOQ1Ofgfua","colab_type":"code","colab":{}},"source":["# Get vocabulary, vocabulary size and numeric word seqeunces for train,test and validation data\n","\n","def stacker(data):\n","  data1=[]\n","  for i in range(0,len(data)):\n","    data1.append(data[i][0] +\" \" + data[i][1])\n","  return data1\n","\n","\n","def getvocab(data):\n","  tokenizer=Tokenizer(split=' ',oov_token=\"UNK\")\n","  tokenizer.fit_on_texts(data)\n","  vocab = list(tokenizer.word_index.keys())\n","  vocab_size = len(vocab)\n","  return tokenizer,vocab,vocab_size\n","\n","def text2sec(tokenizer,data):\n","  X1=[]\n","  X2=[]\n","  #detupling\n","  for i in data:\n","    X1.append(i[0])\n","    X2.append(i[1])\n","  #generating numbers\n","  X1=tokenizer.texts_to_sequences(X1)\n","  X2=tokenizer.texts_to_sequences(X2)\n","  #padding\n","  X1=pad_sequences(X1,padding=\"post\",maxlen=20)\n","  X2=pad_sequences(X2,padding='post',maxlen=20)\n","\n","  \n","\n","  return X1,X2\n","\n","  \n","\n","\n","stacked_train = stacker(train_data)\n","tokenizer,vocab,vocab_size=getvocab(stacked_train)\n","X1,X2=text2sec(tokenizer,train_data)\n","V1,V2=text2sec(tokenizer,valid_data)\n","T1,T2=text2sec(tokenizer,test_data)\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2zTZl-0xMB1B","colab_type":"code","colab":{}},"source":["def one_hot(labels):\n","  label_encoder = LabelEncoder()\n","  integer_encoded = label_encoder.fit_transform(labels)\n","  onehot_encoder = OneHotEncoder(sparse=False)\n","  integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","  onehot_encoded= onehot_encoder.fit_transform(integer_encoded)\n","  return np.array(onehot_encoded)\n","\n","train_labels = one_hot(train_labels)\n","test_labels = one_hot(test_labels)\n","valid_labels = one_hot(valid_labels)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vsDFKuiGwBmi","colab_type":"code","colab":{}},"source":["#loading embeddings\n","#50d\n","path = 'glove.6B.100d.txt'\n","with open(path,'r')as f:\n","  lines=f.readlines()\n","  f.close()\n","d_50={}\n","for i in lines:\n","  line=i.split(\" \")\n","  word=line[0]\n","  d_50[word]=[float(j) for j in line[1:]]\n","#adding 0\n","d_50['UNK']=np.zeros(100,dtype='float')\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJbBms1y4XqN","colab_type":"code","colab":{}},"source":["Emb_dim=100\n","def embed(dict,vocab):\n","  Emb_dim=100\n","  emb_matrix = np.zeros((len(vocab)+1,Emb_dim))\n","  for index,i in enumerate(vocab):\n","      if i in list(d_50.keys()):\n","          emb_matrix[index]=d_50[i]\n","  return emb_matrix\n","\n","d_50_embeddings =embed(d_50,vocab) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cj6uIuRhgfue","colab_type":"text"},"source":["Create the model in the cell below:\n","Try out different sizes for LSTM 50,100,300 and use relu activations. Also report results with Bi-LSTM as well.<br>\n","<i>To boost performance you can try adding a hidden layer between the lstm and output layer and also by adding a dropout layer in between different layers</i>"]},{"cell_type":"markdown","metadata":{"id":"ncMxclappqLK","colab_type":"text"},"source":["# **BILSTM**\n","\n"]},{"cell_type":"code","metadata":{"id":"vcwDWZMXgfue","colab_type":"code","outputId":"b2a59f8c-0b72-4fc6-9125-0bf53b865b41","executionInfo":{"status":"ok","timestamp":1589132336270,"user_tz":-300,"elapsed":111018,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":422}},"source":["# code model here\n","\n","input_layer1=Input(shape=(20,))\n","input_layer2=Input(shape=(20,))\n","emb=Embedding(vocab_size+1,Emb_dim,weights=[d_50_embeddings],input_length=20,trainable=False)\n","first_emb = emb(input_layer1)\n","second_emb = emb(input_layer2)\n","lstm=Bidirectional(LSTM(100,return_state=False,return_sequences=False))\n","out1 = lstm(first_emb)\n","out2=lstm(second_emb)\n","concat = Concatenate()([out1,out2])\n","output=Dense(2,activation='softmax')(concat)\n","\n","model1 = Model(inputs=[input_layer1,input_layer2], outputs=[output])\n","model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n","model1.summary()\n","\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 20, 100)      1066100     input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","bidirectional (Bidirectional)   (None, 200)          160800      embedding[0][0]                  \n","                                                                 embedding[1][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 400)          0           bidirectional[0][0]              \n","                                                                 bidirectional[1][0]              \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2)            802         concatenate[0][0]                \n","==================================================================================================\n","Total params: 1,227,702\n","Trainable params: 161,602\n","Non-trainable params: 1,066,100\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lhXd-fAUpx5i","colab_type":"text"},"source":["# **LSTM**"]},{"cell_type":"code","metadata":{"id":"3yYCUXsRp7z4","colab_type":"code","outputId":"81681847-15b2-446f-e0a1-de30af5707ec","executionInfo":{"status":"ok","timestamp":1589132336271,"user_tz":-300,"elapsed":111012,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":422}},"source":["input_layer1=Input(shape=(20,))\n","input_layer2=Input(shape=(20,))\n","emb=Embedding(vocab_size+1,Emb_dim,weights=[d_50_embeddings],input_length=20,trainable=False)\n","first_emb = emb(input_layer1)\n","second_emb = emb(input_layer2)\n","lstm=LSTM(100,return_state=True,return_sequences=True)\n","_,out1,_ = lstm(first_emb)\n","_,out2,_=lstm(second_emb)\n","concat = Concatenate()([out1,out2])\n","output=Dense(2,activation='softmax')(concat)\n","\n","model2 = Model(inputs=[input_layer1,input_layer2], outputs=[output])\n","model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n","model2.summary()\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 20, 100)      1066100     input_3[0][0]                    \n","                                                                 input_4[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, 20, 100), (N 80400       embedding_1[0][0]                \n","                                                                 embedding_1[1][0]                \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 200)          0           lstm_1[0][1]                     \n","                                                                 lstm_1[1][1]                     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 2)            402         concatenate_1[0][0]              \n","==================================================================================================\n","Total params: 1,146,902\n","Trainable params: 80,802\n","Non-trainable params: 1,066,100\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C0tG3HkGgfui","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n","filepath = \"setting_\" + \"model1\" + \".hdf5\"\n","logfilepath = \"setting_\"+\"model1\" + \".csv\"\n","reduce_lr_rate=0.2\n","logCallback = CSVLogger(logfilepath, separator=',', append=False)\n","earlyStopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='auto')\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_weights_only=True, verbose=1,\n","                             save_best_only=True, mode='auto')\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_rate, patience=10,\n","                              cooldown=0, min_lr=0.0000000001, verbose=0)\n","\n","callbacks_list = [logCallback, earlyStopping, reduce_lr, checkpoint]\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HXKd9s3Vgful","colab_type":"code","outputId":"4d165f81-6428-431b-e2e6-5a861517084a","executionInfo":{"status":"ok","timestamp":1589132445515,"user_tz":-300,"elapsed":220243,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model1.fit([np.array(X1),np.array(X2)],train_labels, epochs=100, batch_size=32,validation_data=(([V1,V2], valid_labels)),verbose=1,shuffle=True,callbacks=callbacks_list)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.6257 - categorical_accuracy: 0.6746WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 3s 30ms/step - loss: 0.6240 - categorical_accuracy: 0.6762 - val_loss: 0.6123 - val_categorical_accuracy: 0.6751 - lr: 0.0010\n","Epoch 2/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.5908 - categorical_accuracy: 0.6911WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.5912 - categorical_accuracy: 0.6907 - val_loss: 0.6593 - val_categorical_accuracy: 0.5990 - lr: 0.0010\n","Epoch 3/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.5624 - categorical_accuracy: 0.7042WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.5627 - categorical_accuracy: 0.7037 - val_loss: 0.6134 - val_categorical_accuracy: 0.6802 - lr: 0.0010\n","Epoch 4/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.5241 - categorical_accuracy: 0.7347WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.5233 - categorical_accuracy: 0.7351 - val_loss: 0.6528 - val_categorical_accuracy: 0.6904 - lr: 0.0010\n","Epoch 5/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.4702 - categorical_accuracy: 0.7777WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.4705 - categorical_accuracy: 0.7781 - val_loss: 0.7045 - val_categorical_accuracy: 0.6447 - lr: 0.0010\n","Epoch 6/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.4124 - categorical_accuracy: 0.8170WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.4160 - categorical_accuracy: 0.8141 - val_loss: 0.7381 - val_categorical_accuracy: 0.6802 - lr: 0.0010\n","Epoch 7/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.3252 - categorical_accuracy: 0.8707WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.3250 - categorical_accuracy: 0.8713 - val_loss: 0.8116 - val_categorical_accuracy: 0.6396 - lr: 0.0010\n","Epoch 8/100\n","89/89 [==============================] - ETA: 0s - loss: 0.2314 - categorical_accuracy: 0.9143WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.2314 - categorical_accuracy: 0.9143 - val_loss: 1.0304 - val_categorical_accuracy: 0.5482 - lr: 0.0010\n","Epoch 9/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.1474 - categorical_accuracy: 0.9553WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.1483 - categorical_accuracy: 0.9538 - val_loss: 1.1636 - val_categorical_accuracy: 0.6041 - lr: 0.0010\n","Epoch 10/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0724 - categorical_accuracy: 0.9814WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0731 - categorical_accuracy: 0.9810 - val_loss: 1.3355 - val_categorical_accuracy: 0.5964 - lr: 0.0010\n","Epoch 11/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0483 - categorical_accuracy: 0.9864WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0491 - categorical_accuracy: 0.9862 - val_loss: 1.4967 - val_categorical_accuracy: 0.5051 - lr: 0.0010\n","Epoch 12/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0253 - categorical_accuracy: 0.9965WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0253 - categorical_accuracy: 0.9965 - val_loss: 1.5795 - val_categorical_accuracy: 0.5761 - lr: 2.0000e-04\n","Epoch 13/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0102 - categorical_accuracy: 0.9996WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0102 - categorical_accuracy: 0.9996 - val_loss: 1.6846 - val_categorical_accuracy: 0.5533 - lr: 2.0000e-04\n","Epoch 14/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0072 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0072 - categorical_accuracy: 1.0000 - val_loss: 1.7613 - val_categorical_accuracy: 0.5711 - lr: 2.0000e-04\n","Epoch 15/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0058 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0057 - categorical_accuracy: 1.0000 - val_loss: 1.8260 - val_categorical_accuracy: 0.5685 - lr: 2.0000e-04\n","Epoch 16/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0046 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0046 - categorical_accuracy: 1.0000 - val_loss: 1.8794 - val_categorical_accuracy: 0.5736 - lr: 2.0000e-04\n","Epoch 17/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0039 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0039 - categorical_accuracy: 1.0000 - val_loss: 1.9415 - val_categorical_accuracy: 0.5685 - lr: 2.0000e-04\n","Epoch 18/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0033 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0033 - categorical_accuracy: 1.0000 - val_loss: 1.9880 - val_categorical_accuracy: 0.5711 - lr: 2.0000e-04\n","Epoch 19/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0028 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0028 - categorical_accuracy: 1.0000 - val_loss: 2.0331 - val_categorical_accuracy: 0.5736 - lr: 2.0000e-04\n","Epoch 20/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0025 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 2.0802 - val_categorical_accuracy: 0.5787 - lr: 2.0000e-04\n","Epoch 21/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 2.1229 - val_categorical_accuracy: 0.5787 - lr: 2.0000e-04\n","Epoch 22/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 2.1285 - val_categorical_accuracy: 0.5787 - lr: 4.0000e-05\n","Epoch 23/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 2.1362 - val_categorical_accuracy: 0.5787 - lr: 4.0000e-05\n","Epoch 24/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0018 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 2.1441 - val_categorical_accuracy: 0.5761 - lr: 4.0000e-05\n","Epoch 25/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0018 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 2.1539 - val_categorical_accuracy: 0.5761 - lr: 4.0000e-05\n","Epoch 26/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.1628 - val_categorical_accuracy: 0.5761 - lr: 4.0000e-05\n","Epoch 27/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.1730 - val_categorical_accuracy: 0.5761 - lr: 4.0000e-05\n","Epoch 28/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.1823 - val_categorical_accuracy: 0.5736 - lr: 4.0000e-05\n","Epoch 29/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.1920 - val_categorical_accuracy: 0.5736 - lr: 4.0000e-05\n","Epoch 30/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 2.2018 - val_categorical_accuracy: 0.5736 - lr: 4.0000e-05\n","Epoch 31/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 2.2126 - val_categorical_accuracy: 0.5736 - lr: 4.0000e-05\n","Epoch 32/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 2.2148 - val_categorical_accuracy: 0.5736 - lr: 8.0000e-06\n","Epoch 33/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 2.2171 - val_categorical_accuracy: 0.5736 - lr: 8.0000e-06\n","Epoch 34/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 2.2195 - val_categorical_accuracy: 0.5736 - lr: 8.0000e-06\n","Epoch 35/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 2.2220 - val_categorical_accuracy: 0.5736 - lr: 8.0000e-06\n","Epoch 36/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 2.2243 - val_categorical_accuracy: 0.5736 - lr: 8.0000e-06\n","Epoch 37/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 2.2272 - val_categorical_accuracy: 0.5736 - lr: 8.0000e-06\n","Epoch 38/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 2.2297 - val_categorical_accuracy: 0.5736 - lr: 8.0000e-06\n","Epoch 39/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 2.2324 - val_categorical_accuracy: 0.5736 - lr: 8.0000e-06\n","Epoch 40/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 2.2353 - val_categorical_accuracy: 0.5736 - lr: 8.0000e-06\n","Epoch 41/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 2.2382 - val_categorical_accuracy: 0.5736 - lr: 8.0000e-06\n","Epoch 42/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2388 - val_categorical_accuracy: 0.5736 - lr: 1.6000e-06\n","Epoch 43/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2395 - val_categorical_accuracy: 0.5736 - lr: 1.6000e-06\n","Epoch 44/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2401 - val_categorical_accuracy: 0.5736 - lr: 1.6000e-06\n","Epoch 45/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2409 - val_categorical_accuracy: 0.5736 - lr: 1.6000e-06\n","Epoch 46/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2416 - val_categorical_accuracy: 0.5736 - lr: 1.6000e-06\n","Epoch 47/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2423 - val_categorical_accuracy: 0.5736 - lr: 1.6000e-06\n","Epoch 48/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2431 - val_categorical_accuracy: 0.5736 - lr: 1.6000e-06\n","Epoch 49/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2440 - val_categorical_accuracy: 0.5736 - lr: 1.6000e-06\n","Epoch 50/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2448 - val_categorical_accuracy: 0.5736 - lr: 1.6000e-06\n","Epoch 51/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2457 - val_categorical_accuracy: 0.5736 - lr: 1.6000e-06\n","Epoch 52/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2459 - val_categorical_accuracy: 0.5736 - lr: 3.2000e-07\n","Epoch 53/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2461 - val_categorical_accuracy: 0.5736 - lr: 3.2000e-07\n","Epoch 54/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2463 - val_categorical_accuracy: 0.5736 - lr: 3.2000e-07\n","Epoch 55/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2464 - val_categorical_accuracy: 0.5736 - lr: 3.2000e-07\n","Epoch 56/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2467 - val_categorical_accuracy: 0.5736 - lr: 3.2000e-07\n","Epoch 57/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2469 - val_categorical_accuracy: 0.5736 - lr: 3.2000e-07\n","Epoch 58/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2471 - val_categorical_accuracy: 0.5736 - lr: 3.2000e-07\n","Epoch 59/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2474 - val_categorical_accuracy: 0.5736 - lr: 3.2000e-07\n","Epoch 60/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2477 - val_categorical_accuracy: 0.5736 - lr: 3.2000e-07\n","Epoch 61/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2479 - val_categorical_accuracy: 0.5736 - lr: 3.2000e-07\n","Epoch 62/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2480 - val_categorical_accuracy: 0.5736 - lr: 6.4000e-08\n","Epoch 63/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2480 - val_categorical_accuracy: 0.5736 - lr: 6.4000e-08\n","Epoch 64/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2481 - val_categorical_accuracy: 0.5736 - lr: 6.4000e-08\n","Epoch 65/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2481 - val_categorical_accuracy: 0.5736 - lr: 6.4000e-08\n","Epoch 66/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2482 - val_categorical_accuracy: 0.5736 - lr: 6.4000e-08\n","Epoch 67/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2483 - val_categorical_accuracy: 0.5736 - lr: 6.4000e-08\n","Epoch 68/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2483 - val_categorical_accuracy: 0.5736 - lr: 6.4000e-08\n","Epoch 69/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2484 - val_categorical_accuracy: 0.5736 - lr: 6.4000e-08\n","Epoch 70/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2485 - val_categorical_accuracy: 0.5736 - lr: 6.4000e-08\n","Epoch 71/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2485 - val_categorical_accuracy: 0.5736 - lr: 6.4000e-08\n","Epoch 72/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2485 - val_categorical_accuracy: 0.5736 - lr: 1.2800e-08\n","Epoch 73/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2485 - val_categorical_accuracy: 0.5736 - lr: 1.2800e-08\n","Epoch 74/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 1.2800e-08\n","Epoch 75/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 1.2800e-08\n","Epoch 76/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 1.2800e-08\n","Epoch 77/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 1.2800e-08\n","Epoch 78/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 1.2800e-08\n","Epoch 79/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 1.2800e-08\n","Epoch 80/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 1.2800e-08\n","Epoch 81/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 1.2800e-08\n","Epoch 82/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 2.5600e-09\n","Epoch 83/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 2.5600e-09\n","Epoch 84/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 2.5600e-09\n","Epoch 85/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 2.5600e-09\n","Epoch 86/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 2.5600e-09\n","Epoch 87/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 2.5600e-09\n","Epoch 88/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 2.5600e-09\n","Epoch 89/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 2.5600e-09\n","Epoch 90/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 2.5600e-09\n","Epoch 91/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 2.5600e-09\n","Epoch 92/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 5.1200e-10\n","Epoch 93/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 5.1200e-10\n","Epoch 94/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 5.1200e-10\n","Epoch 95/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 5.1200e-10\n","Epoch 96/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 5.1200e-10\n","Epoch 97/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 5.1200e-10\n","Epoch 98/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 5.1200e-10\n","Epoch 99/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 5.1200e-10\n","Epoch 100/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 11ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 2.2486 - val_categorical_accuracy: 0.5736 - lr: 5.1200e-10\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f1a505fbda0>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"FN2H-H6DqKat","colab_type":"code","outputId":"a4ed4195-972f-4db5-a822-045ea7086b90","executionInfo":{"status":"ok","timestamp":1589132507191,"user_tz":-300,"elapsed":281913,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model2.fit([np.array(X1),np.array(X2)],train_labels, epochs=100, batch_size=32,validation_data=(([V1,V2], valid_labels)),verbose=1,shuffle=True,callbacks=callbacks_list)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.6296 - categorical_accuracy: 0.6731WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 13ms/step - loss: 0.6292 - categorical_accuracy: 0.6737 - val_loss: 0.6229 - val_categorical_accuracy: 0.6802 - lr: 0.0010\n","Epoch 2/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.6065 - categorical_accuracy: 0.6845WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.6056 - categorical_accuracy: 0.6847 - val_loss: 0.6481 - val_categorical_accuracy: 0.6244 - lr: 0.0010\n","Epoch 3/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.5949 - categorical_accuracy: 0.6846WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.5966 - categorical_accuracy: 0.6829 - val_loss: 0.6190 - val_categorical_accuracy: 0.6802 - lr: 0.0010\n","Epoch 4/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.5702 - categorical_accuracy: 0.7109WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.5706 - categorical_accuracy: 0.7108 - val_loss: 0.6544 - val_categorical_accuracy: 0.6142 - lr: 0.0010\n","Epoch 5/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.5518 - categorical_accuracy: 0.7256WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.5533 - categorical_accuracy: 0.7231 - val_loss: 0.6450 - val_categorical_accuracy: 0.6396 - lr: 0.0010\n","Epoch 6/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.5168 - categorical_accuracy: 0.7460WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.5178 - categorical_accuracy: 0.7467 - val_loss: 0.6514 - val_categorical_accuracy: 0.6396 - lr: 0.0010\n","Epoch 7/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.4719 - categorical_accuracy: 0.7702WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.4710 - categorical_accuracy: 0.7735 - val_loss: 0.6907 - val_categorical_accuracy: 0.6675 - lr: 0.0010\n","Epoch 8/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.4096 - categorical_accuracy: 0.8168WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.4102 - categorical_accuracy: 0.8166 - val_loss: 0.7344 - val_categorical_accuracy: 0.6472 - lr: 0.0010\n","Epoch 9/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.3202 - categorical_accuracy: 0.8672WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.3210 - categorical_accuracy: 0.8660 - val_loss: 0.8986 - val_categorical_accuracy: 0.6345 - lr: 0.0010\n","Epoch 10/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.2292 - categorical_accuracy: 0.9138WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.2314 - categorical_accuracy: 0.9129 - val_loss: 1.0837 - val_categorical_accuracy: 0.6421 - lr: 0.0010\n","Epoch 11/100\n","82/89 [==========================>...] - ETA: 0s - loss: 0.1499 - categorical_accuracy: 0.9447WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.1513 - categorical_accuracy: 0.9450 - val_loss: 1.2828 - val_categorical_accuracy: 0.5939 - lr: 0.0010\n","Epoch 12/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.1060 - categorical_accuracy: 0.9652WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.1061 - categorical_accuracy: 0.9654 - val_loss: 1.2621 - val_categorical_accuracy: 0.5990 - lr: 0.0010\n","Epoch 13/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0839 - categorical_accuracy: 0.9717WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0833 - categorical_accuracy: 0.9718 - val_loss: 1.5701 - val_categorical_accuracy: 0.6244 - lr: 0.0010\n","Epoch 14/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0290 - categorical_accuracy: 0.9949WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0287 - categorical_accuracy: 0.9951 - val_loss: 1.7736 - val_categorical_accuracy: 0.6142 - lr: 2.0000e-04\n","Epoch 15/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0147 - categorical_accuracy: 0.9989WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0146 - categorical_accuracy: 0.9989 - val_loss: 1.8897 - val_categorical_accuracy: 0.6091 - lr: 2.0000e-04\n","Epoch 16/100\n","80/89 [=========================>....] - ETA: 0s - loss: 0.0102 - categorical_accuracy: 0.9996WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0100 - categorical_accuracy: 0.9996 - val_loss: 1.9952 - val_categorical_accuracy: 0.6142 - lr: 2.0000e-04\n","Epoch 17/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0078 - categorical_accuracy: 0.9996WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0077 - categorical_accuracy: 0.9996 - val_loss: 2.0799 - val_categorical_accuracy: 0.6091 - lr: 2.0000e-04\n","Epoch 18/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0062 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0062 - categorical_accuracy: 1.0000 - val_loss: 2.1436 - val_categorical_accuracy: 0.6168 - lr: 2.0000e-04\n","Epoch 19/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0051 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0051 - categorical_accuracy: 1.0000 - val_loss: 2.2131 - val_categorical_accuracy: 0.6168 - lr: 2.0000e-04\n","Epoch 20/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0043 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0043 - categorical_accuracy: 1.0000 - val_loss: 2.2781 - val_categorical_accuracy: 0.6193 - lr: 2.0000e-04\n","Epoch 21/100\n","82/89 [==========================>...] - ETA: 0s - loss: 0.0037 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0036 - categorical_accuracy: 1.0000 - val_loss: 2.3253 - val_categorical_accuracy: 0.6142 - lr: 2.0000e-04\n","Epoch 22/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0031 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0032 - categorical_accuracy: 1.0000 - val_loss: 2.3890 - val_categorical_accuracy: 0.6168 - lr: 2.0000e-04\n","Epoch 23/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.0028 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0027 - categorical_accuracy: 1.0000 - val_loss: 2.4384 - val_categorical_accuracy: 0.6193 - lr: 2.0000e-04\n","Epoch 24/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.0024 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0024 - categorical_accuracy: 1.0000 - val_loss: 2.4476 - val_categorical_accuracy: 0.6193 - lr: 4.0000e-05\n","Epoch 25/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0023 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 2.4570 - val_categorical_accuracy: 0.6193 - lr: 4.0000e-05\n","Epoch 26/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0023 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 2.4689 - val_categorical_accuracy: 0.6193 - lr: 4.0000e-05\n","Epoch 27/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 2.4804 - val_categorical_accuracy: 0.6193 - lr: 4.0000e-05\n","Epoch 28/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 2.4923 - val_categorical_accuracy: 0.6193 - lr: 4.0000e-05\n","Epoch 29/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0021 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0021 - categorical_accuracy: 1.0000 - val_loss: 2.5046 - val_categorical_accuracy: 0.6193 - lr: 4.0000e-05\n","Epoch 30/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0021 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 2.5166 - val_categorical_accuracy: 0.6193 - lr: 4.0000e-05\n","Epoch 31/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0020 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 2.5306 - val_categorical_accuracy: 0.6193 - lr: 4.0000e-05\n","Epoch 32/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 2.5415 - val_categorical_accuracy: 0.6218 - lr: 4.0000e-05\n","Epoch 33/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 2.5544 - val_categorical_accuracy: 0.6218 - lr: 4.0000e-05\n","Epoch 34/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0018 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 2.5574 - val_categorical_accuracy: 0.6218 - lr: 8.0000e-06\n","Epoch 35/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0018 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 2.5599 - val_categorical_accuracy: 0.6218 - lr: 8.0000e-06\n","Epoch 36/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0018 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 2.5634 - val_categorical_accuracy: 0.6218 - lr: 8.0000e-06\n","Epoch 37/100\n","82/89 [==========================>...] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 2.5662 - val_categorical_accuracy: 0.6218 - lr: 8.0000e-06\n","Epoch 38/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.5693 - val_categorical_accuracy: 0.6218 - lr: 8.0000e-06\n","Epoch 39/100\n","82/89 [==========================>...] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.5730 - val_categorical_accuracy: 0.6218 - lr: 8.0000e-06\n","Epoch 40/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.5763 - val_categorical_accuracy: 0.6218 - lr: 8.0000e-06\n","Epoch 41/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.5797 - val_categorical_accuracy: 0.6218 - lr: 8.0000e-06\n","Epoch 42/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.5835 - val_categorical_accuracy: 0.6218 - lr: 8.0000e-06\n","Epoch 43/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.5869 - val_categorical_accuracy: 0.6218 - lr: 8.0000e-06\n","Epoch 44/100\n","81/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.5878 - val_categorical_accuracy: 0.6218 - lr: 1.6000e-06\n","Epoch 45/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.5886 - val_categorical_accuracy: 0.6218 - lr: 1.6000e-06\n","Epoch 46/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.5893 - val_categorical_accuracy: 0.6218 - lr: 1.6000e-06\n","Epoch 47/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.5903 - val_categorical_accuracy: 0.6193 - lr: 1.6000e-06\n","Epoch 48/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 2.5913 - val_categorical_accuracy: 0.6193 - lr: 1.6000e-06\n","Epoch 49/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5922 - val_categorical_accuracy: 0.6193 - lr: 1.6000e-06\n","Epoch 50/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5932 - val_categorical_accuracy: 0.6193 - lr: 1.6000e-06\n","Epoch 51/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5942 - val_categorical_accuracy: 0.6193 - lr: 1.6000e-06\n","Epoch 52/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5954 - val_categorical_accuracy: 0.6193 - lr: 1.6000e-06\n","Epoch 53/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5964 - val_categorical_accuracy: 0.6193 - lr: 1.6000e-06\n","Epoch 54/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5967 - val_categorical_accuracy: 0.6193 - lr: 3.2000e-07\n","Epoch 55/100\n","82/89 [==========================>...] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5969 - val_categorical_accuracy: 0.6193 - lr: 3.2000e-07\n","Epoch 56/100\n","81/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5971 - val_categorical_accuracy: 0.6193 - lr: 3.2000e-07\n","Epoch 57/100\n","81/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5974 - val_categorical_accuracy: 0.6193 - lr: 3.2000e-07\n","Epoch 58/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5977 - val_categorical_accuracy: 0.6193 - lr: 3.2000e-07\n","Epoch 59/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5980 - val_categorical_accuracy: 0.6193 - lr: 3.2000e-07\n","Epoch 60/100\n","81/89 [==========================>...] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5983 - val_categorical_accuracy: 0.6193 - lr: 3.2000e-07\n","Epoch 61/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5985 - val_categorical_accuracy: 0.6193 - lr: 3.2000e-07\n","Epoch 62/100\n","82/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5989 - val_categorical_accuracy: 0.6193 - lr: 3.2000e-07\n","Epoch 63/100\n","82/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5992 - val_categorical_accuracy: 0.6193 - lr: 3.2000e-07\n","Epoch 64/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5993 - val_categorical_accuracy: 0.6193 - lr: 6.4000e-08\n","Epoch 65/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5993 - val_categorical_accuracy: 0.6193 - lr: 6.4000e-08\n","Epoch 66/100\n","89/89 [==============================] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5994 - val_categorical_accuracy: 0.6193 - lr: 6.4000e-08\n","Epoch 67/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5995 - val_categorical_accuracy: 0.6193 - lr: 6.4000e-08\n","Epoch 68/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5996 - val_categorical_accuracy: 0.6193 - lr: 6.4000e-08\n","Epoch 69/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5996 - val_categorical_accuracy: 0.6193 - lr: 6.4000e-08\n","Epoch 70/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5997 - val_categorical_accuracy: 0.6193 - lr: 6.4000e-08\n","Epoch 71/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5998 - val_categorical_accuracy: 0.6193 - lr: 6.4000e-08\n","Epoch 72/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.5999 - val_categorical_accuracy: 0.6193 - lr: 6.4000e-08\n","Epoch 73/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6000 - val_categorical_accuracy: 0.6193 - lr: 6.4000e-08\n","Epoch 74/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6000 - val_categorical_accuracy: 0.6193 - lr: 1.2800e-08\n","Epoch 75/100\n","88/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6000 - val_categorical_accuracy: 0.6193 - lr: 1.2800e-08\n","Epoch 76/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6000 - val_categorical_accuracy: 0.6193 - lr: 1.2800e-08\n","Epoch 77/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6000 - val_categorical_accuracy: 0.6193 - lr: 1.2800e-08\n","Epoch 78/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6000 - val_categorical_accuracy: 0.6193 - lr: 1.2800e-08\n","Epoch 79/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6000 - val_categorical_accuracy: 0.6193 - lr: 1.2800e-08\n","Epoch 80/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 1.2800e-08\n","Epoch 81/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 1.2800e-08\n","Epoch 82/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 1.2800e-08\n","Epoch 83/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 1.2800e-08\n","Epoch 84/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 2.5600e-09\n","Epoch 85/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 2.5600e-09\n","Epoch 86/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 2.5600e-09\n","Epoch 87/100\n","85/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 2.5600e-09\n","Epoch 88/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 2.5600e-09\n","Epoch 89/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 2.5600e-09\n","Epoch 90/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 2.5600e-09\n","Epoch 91/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 2.5600e-09\n","Epoch 92/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 2.5600e-09\n","Epoch 93/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 2.5600e-09\n","Epoch 94/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 5.1200e-10\n","Epoch 95/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 5.1200e-10\n","Epoch 96/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 5.1200e-10\n","Epoch 97/100\n","87/89 [============================>.] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 5.1200e-10\n","Epoch 98/100\n","84/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 5.1200e-10\n","Epoch 99/100\n","83/89 [==========================>...] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 7ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 5.1200e-10\n","Epoch 100/100\n","86/89 [===========================>..] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 2.6001 - val_categorical_accuracy: 0.6193 - lr: 5.1200e-10\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f1a4c285cc0>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"1UWTV5_Ogfun","colab_type":"text"},"source":["Use the <b>model.predict</b> method to get predictions. There predictions will be a probability distribution over the lables, to get the desired class take the max value in a prediction vector as the predicted class.<br>"]},{"cell_type":"markdown","metadata":{"id":"ooUVD7oiqWj8","colab_type":"text"},"source":["# **LSTM**\n","\n"]},{"cell_type":"code","metadata":{"id":"BSacRlx0gfuo","colab_type":"code","outputId":"88ae5118-0661-4fa8-9dca-edb7d0839026","executionInfo":{"status":"ok","timestamp":1589132508738,"user_tz":-300,"elapsed":283453,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":436}},"source":["#predictions = code here\n","labelList=[\"No\",\"Yes\"]\n","predictions = model2.predict([T1,T2])\n","\n","pred=[]\n","for i in predictions:\n","    pred.append(np.argmax(i))\n","predictions=pred\n","\n","from sklearn.metrics import confusion_matrix\n","\n","test_Y_max=np.argmax(test_labels, axis=-1)\n","cm=confusion_matrix(test_Y_max,predictions)\n","cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n","plt.figure(figsize=(10,7))\n","sn.set(font_scale=1.4) # for label size\n","sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n","plt.show()"],"execution_count":19,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x504 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"5nFe4yelsD58","colab_type":"code","outputId":"13cbc5ef-93a3-4917-9e95-3a249a49ee03","executionInfo":{"status":"ok","timestamp":1589132508739,"user_tz":-300,"elapsed":283447,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = labelList))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Classification Report\n","               precision    recall  f1-score   support\n","\n","          No       0.39      0.37      0.38       227\n","         Yes       0.71      0.72      0.72       482\n","\n","    accuracy                           0.61       709\n","   macro avg       0.55      0.55      0.55       709\n","weighted avg       0.61      0.61      0.61       709\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V0EspGeTqSsV","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"i8wojvy0pOs_","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"4JcFU-PrqpHQ","colab_type":"text"},"source":["# **BILSTM**"]},{"cell_type":"code","metadata":{"id":"h1LqV4rQoUeb","colab_type":"code","outputId":"563d546f-0abf-45cb-f017-550c051ae969","executionInfo":{"status":"ok","timestamp":1589132509661,"user_tz":-300,"elapsed":284364,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":436}},"source":["#predictions = code here\n","labelList=[\"NO\",\"Yes\"]\n","predictions = model1.predict([T1,T2])\n","\n","pred=[]\n","for i in predictions:\n","    pred.append(np.argmax(i))\n","predictions=pred\n","\n","from sklearn.metrics import confusion_matrix\n","\n","test_Y_max=np.argmax(test_labels, axis=-1)\n","cm=confusion_matrix(test_Y_max,predictions)\n","cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n","plt.figure(figsize=(10,7))\n","sn.set(font_scale=1.4) # for label size\n","sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n","plt.show()"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x504 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"769xlrb2gfur","colab_type":"code","outputId":"3818fd2c-4470-43fe-921c-a9e03519d5a9","executionInfo":{"status":"ok","timestamp":1589132509661,"user_tz":-300,"elapsed":284358,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = labelList))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Classification Report\n","               precision    recall  f1-score   support\n","\n","          NO       0.40      0.44      0.42       227\n","         Yes       0.72      0.69      0.71       482\n","\n","    accuracy                           0.61       709\n","   macro avg       0.56      0.57      0.56       709\n","weighted avg       0.62      0.61      0.62       709\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0EzEQCA1gfuw","colab_type":"text"},"source":["# Task 2 Sentiment Classification\n","For this task we will be reusing the movie reviews dataset available on <a href=\"https://www.kaggle.com/c/word2vec-nlp-tutorial/data\">kaggle</a> and download the dataset from there. \n","We will be using the unlabeledTrainData file and labeledTrainData file. We will use the gensim package to train word2vec embeddings using [gensim](https://radimrehurek.com/gensim/) package and unlabelled train data as in the previous assignmnet. Now instead for creating a single representation for each review we will be using deep learning models for this task. We will use the same archetecture as before but will experiment with different reccurant networks namely RNN, GRU and LSTM.<br> This task might feel like <a href=\"https://ibb.co/Tgh2XyH\">this</a> but since this is a deep learning assignment thus we must use it.\n","<h3>Data Preperation</h3>\n","<ul>\n","    <li> First we need to preprocess the data, convert the data to lower casing(both files). Any other preprocessing procedures are optional but keep in mind that this will affect the performance of your model.</li>\n","    <li> Split the labeledTrainData data file into test, train and validation in the ratio 20,70,10. Use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">scikit_test_train_split</a> <br><i><b>Hint:</b> use the splitter twice to get desired data splits.</i></li>\n","    <li> Next we need the vocabulary, vocabulary size and to convert sentences to numeric sequences by representing each word with a numeric value which will make our implementation easier later on, use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\">Tokenizer</a> from keras. <br><i>(Fit the tokenizer on train data and use the same tokenizer to convert train,test and validation data to numeric sequences)</i> </li>\n","    <li>  Use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\"> pad sequences</a> to add post padding to all sentences that are shorter than maximum sequence length</li>\n","    <li> Use one hot representation for targets/labels, you can use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">scikit learn</a> or <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing\">keras preprocessing</a>.</li>\n","</ul>\n","<h3>Loading embeddings</h3>\n","<ul>\n","    <li> As state before use the gensim package to train the word2vec model on unlabelledTrainData file</li>\n","    <li> Next we will create a dictionary for our dataset's vocabulary. Copy all the word embeddings for words that are in our vocabulary and in the word2vec model, if a word exists in our vocabulary but does not exist in word2vec model create a zero vector of embedding dimension size and add it to the dictionary.</li>\n","</ul>\n","<h3>Create Model</h3>\n","<ul>\n","    <li> Here is a visual for the model <img src=\"sentimentdeep.png\">\n","    <li> Create the model using <a href\"https://www.tensorflow.org/guide/keras/functional\">functional API</a> or the <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\">Sequential API</a></li>\n","    <li> Hints: The emebedding layer has a parameter that allows you to use pretrained embeddings</li>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1RG-swyagfuw","colab_type":"text"},"source":["Use can reuse the code snippets from above for call backs, prediction heat map and classification report\n","<i>You will have provide a label list for this specific dataset inorder for them to run, you are to make the required changes yourself</i>"]},{"cell_type":"code","metadata":{"id":"9bnYBVEpgfux","colab_type":"code","outputId":"e49ba564-5650-4eac-ad24-ad0f3d61529f","executionInfo":{"status":"ok","timestamp":1589134671561,"user_tz":-300,"elapsed":2451,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#loading data \n","import pandas as pd\n","unlabeled=pd.read_table('unlabeledTrainData.tsv',sep=\"\\t\",error_bad_lines=False,encoding='utf-8')\n","unlabeled=list(unlabeled['review'].str.lower())\n","labeled=pd.read_csv('labeledTrainData.tsv',sep='\\t',encoding='utf-8')\n","labels = list(labeled['sentiment'])\n","data  = (labeled['review'].str.lower())\n","\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["b'Skipping line 43043: expected 2 fields, saw 3\\n'\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"RQl-J9n7gfu0","colab_type":"code","colab":{}},"source":["def preprocessing(data):\n","    \"\"\"\n","    Return preprocessed data\n","\n","    Args:\n","        data : sentence pairs\n","    \n","    Returns: preprocessed_data\n","    preprocessed_data : preprocessed dataset \n","    \"\"\"\n","    #keeping alphabets and numbers only \n","    for i in range(0,len(data)):\n","      data[i]=\" \".join((re.findall('[a-z0-9]+',str(data[i]))))\n","    \n","    #removing stop words and len(w) == 2\n","    stop_w=set(stopwords.words('english'))\n","    for i in range(0,len(data)):\n","      tokenized=data[i].split(\" \")\n","      filtered=[k for k in tokenized if k not in stop_w and len(k) > 2 ]\n","      data[i]=\" \".join(filtered)\n","\n","    #Truncating\n","    for i in range(0,len(data)):\n","      tokenized=data[i].split(\" \")\n","      if len(tokenized) > 20:\n","        data[i]=\" \".join(tokenized[:20])\n","\n","    return data\n","\n","unlabel_data = preprocessing(unlabeled)\n","label_data   = preprocessing(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0-cpp64tp9z","colab_type":"code","colab":{}},"source":["for i in range(0,len(unlabel_data)):\n","  unlabel_data[i]=unlabel_data[i].split(\" \")\n","for j in range(0,len(label_data)):\n","  label_data[j]=label_data[j].split(\" \")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oDahW9xNAiH7","colab_type":"code","outputId":"04f5b94b-99bf-4168-e0a5-e63b36b26af1","executionInfo":{"status":"ok","timestamp":1589134697800,"user_tz":-300,"elapsed":16918,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["\n","from gensim.models import Word2Vec\n","def word2vec(data):\n","  path = get_tmpfile(\"word2vec.model\")\n","  model = Word2Vec(data, size=100, window=5, min_count=1, workers=4)\n","  model.save(\"word2vec.model\")\n","  return model\n","\n","wordvec=word2vec(unlabel_data)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OgL6LvE8gfu2","colab_type":"code","colab":{}},"source":["copy1=unlabel_data\n","def getvocab(data):\n","  tokenizer=Tokenizer(oov_token=\"UNK\")\n","  tokenizer.fit_on_texts(data)\n","  vocab = list(tokenizer.word_index.keys())\n","  vocab_size = len(vocab)\n","  return tokenizer,vocab,vocab_size\n","\n","def text2sec(tokenizer,data):\n","\n","  #generating numbers\n","  seq=tokenizer.texts_to_sequences(data)\n","  #padding\n","  seq=pad_sequences(seq,padding=\"post\",maxlen=30)\n","\n","  return seq\n","tokenizer,vocab,vocab_size=getvocab(copy1)\n","unlabel_data=text2sec(tokenizer,unlabel_data)\n","label_data=text2sec(tokenizer,label_data)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FVJ92a7a_7aP","colab_type":"code","colab":{}},"source":["def testTrainSplit(data_X,data_Y):\n","    \"\"\"\n","    Return test train data\n","\n","    Args:\n","        data_X : sentence pairs\n","        data_Y: labels\n","        \n","    Returns: test train and validation split data \n","    \"\"\"\n","    train_data,valid_data,train_labels,valid_labels=splitter(data_X,data_Y,train_size=0.9,test_size=0.1,shuffle=True)\n","    train_data,test_data,train_labels,test_labels=splitter(train_data,train_labels,train_size=0.8,test_size=0.2,shuffle=True)\n","\n","    return train_data,train_labels,test_data,test_labels,valid_data,valid_labels\n","\n","train_data,train_labels,test_data,test_labels,valid_data,valid_labels=testTrainSplit(label_data,labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ZTm1BRJIJGJ","colab_type":"code","outputId":"48c990cc-ce5f-42ad-e834-1eefd13a6248","executionInfo":{"status":"ok","timestamp":1589134699224,"user_tz":-300,"elapsed":15579,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["def embed(model,vocab):\n","  Emb_dim=100\n","  emb_matrix = np.zeros((len(vocab)+1,Emb_dim))\n","  for index,i in enumerate(vocab):\n","      try:\n","        emb_matrix[index]=model[i]\n","      except:\n","        continue\n","  return emb_matrix\n","\n","d_100_embeddings =embed(wordvec,vocab) \n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"j20xtMCUKPlZ","colab_type":"code","colab":{}},"source":["def one_hot(labels):\n","  label_encoder = LabelEncoder()\n","  integer_encoded = label_encoder.fit_transform(labels)\n","  onehot_encoder = OneHotEncoder(sparse=False)\n","  integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","  onehot_encoded= onehot_encoder.fit_transform(integer_encoded)\n","  return np.array(onehot_encoded)\n","\n","train_Labels=one_hot(train_labels)\n","test_Labels=one_hot(test_labels)\n","valid_Labels=one_hot(valid_labels)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQXrhEPnZlVC","colab_type":"text"},"source":["#**GRU**"]},{"cell_type":"code","metadata":{"id":"KOyDEiVZJbtp","colab_type":"code","outputId":"a7cfa7bd-bdbe-42d6-da13-af9aacf703ea","executionInfo":{"status":"ok","timestamp":1589134701989,"user_tz":-300,"elapsed":2732,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":334}},"source":["import tensorflow as tf\n","Emb_dim=100\n","input_layer=Input(shape=(30,))\n","emb=Embedding(vocab_size+1,Emb_dim,weights=[d_100_embeddings],input_length=30,trainable=False)\n","emb_out=emb(input_layer)\n","GRU=tf.keras.layers.GRU(100)\n","out = GRU(emb_out)\n","hidden = Dense(50,activation='relu')\n","out_hidden=hidden(out)\n","output=Dense(2,activation='softmax')(out_hidden)\n","\n","model3 = Model(inputs=[input_layer], outputs=[output])\n","model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n","model3.summary()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 30)]              0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 30, 100)           4470800   \n","_________________________________________________________________\n","gru (GRU)                    (None, 100)               60600     \n","_________________________________________________________________\n","dense (Dense)                (None, 50)                5050      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 102       \n","=================================================================\n","Total params: 4,536,552\n","Trainable params: 65,752\n","Non-trainable params: 4,470,800\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vd0cm6JWZueo","colab_type":"text"},"source":["#**LSTM**"]},{"cell_type":"code","metadata":{"id":"RPzcuFQWZ7rl","colab_type":"code","outputId":"5b1c1330-45f2-4bbe-8701-71b023b56169","executionInfo":{"status":"ok","timestamp":1589134701990,"user_tz":-300,"elapsed":2718,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":298}},"source":["import tensorflow as tf\n","Emb_dim=100\n","input_layer=Input(shape=(30,))\n","emb=Embedding(vocab_size+1,Emb_dim,weights=[d_100_embeddings],input_length=30,trainable=False)\n","emb_out=emb(input_layer)\n","lstm=tf.keras.layers.LSTM(100,return_sequences=True,return_state=True)\n","_,out,_ = lstm(emb_out)\n","output=Dense(2,activation='softmax')(out)\n","\n","model4 = Model(inputs=[input_layer], outputs=[output])\n","model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n","model4.summary()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 30)]              0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 30, 100)           4470800   \n","_________________________________________________________________\n","lstm (LSTM)                  [(None, 30, 100), (None,  80400     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 202       \n","=================================================================\n","Total params: 4,551,402\n","Trainable params: 80,602\n","Non-trainable params: 4,470,800\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3YpX__AZLeEX","colab_type":"code","outputId":"5ab21ee2-ae26-4faa-9524-87fb2c1cf860","executionInfo":{"status":"ok","timestamp":1589134756136,"user_tz":-300,"elapsed":54136,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model3.fit(np.array(train_data),np.array(train_Labels), epochs=20, batch_size=32,verbose=1,validation_data=(np.array(valid_data),np.array(valid_Labels)),shuffle=True,callbacks=callbacks_list)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","550/563 [============================>.] - ETA: 0s - loss: 0.6933 - categorical_accuracy: 0.4984WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 5ms/step - loss: 0.6933 - categorical_accuracy: 0.4981 - val_loss: 0.6933 - val_categorical_accuracy: 0.4932 - lr: 0.0010\n","Epoch 2/20\n","558/563 [============================>.] - ETA: 0s - loss: 0.6932 - categorical_accuracy: 0.4999WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.6932 - categorical_accuracy: 0.4996 - val_loss: 0.6931 - val_categorical_accuracy: 0.5068 - lr: 0.0010\n","Epoch 3/20\n","552/563 [============================>.] - ETA: 0s - loss: 0.6932 - categorical_accuracy: 0.5005WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.6932 - categorical_accuracy: 0.5001 - val_loss: 0.6932 - val_categorical_accuracy: 0.4932 - lr: 0.0010\n","Epoch 4/20\n","563/563 [==============================] - ETA: 0s - loss: 0.6932 - categorical_accuracy: 0.4990WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.6932 - categorical_accuracy: 0.4990 - val_loss: 0.6934 - val_categorical_accuracy: 0.4932 - lr: 0.0010\n","Epoch 5/20\n","556/563 [============================>.] - ETA: 0s - loss: 0.6932 - categorical_accuracy: 0.4982WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.6932 - categorical_accuracy: 0.4986 - val_loss: 0.6933 - val_categorical_accuracy: 0.4932 - lr: 0.0010\n","Epoch 6/20\n","560/563 [============================>.] - ETA: 0s - loss: 0.6932 - categorical_accuracy: 0.4975WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.6932 - categorical_accuracy: 0.4978 - val_loss: 0.6932 - val_categorical_accuracy: 0.4932 - lr: 0.0010\n","Epoch 7/20\n","553/563 [============================>.] - ETA: 0s - loss: 0.6937 - categorical_accuracy: 0.4997WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.6936 - categorical_accuracy: 0.4996 - val_loss: 0.6931 - val_categorical_accuracy: 0.4988 - lr: 0.0010\n","Epoch 8/20\n","561/563 [============================>.] - ETA: 0s - loss: 0.6932 - categorical_accuracy: 0.4965WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.6932 - categorical_accuracy: 0.4971 - val_loss: 0.6931 - val_categorical_accuracy: 0.5104 - lr: 0.0010\n","Epoch 9/20\n","559/563 [============================>.] - ETA: 0s - loss: 0.6927 - categorical_accuracy: 0.5074WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.6927 - categorical_accuracy: 0.5076 - val_loss: 0.6825 - val_categorical_accuracy: 0.5548 - lr: 0.0010\n","Epoch 10/20\n","551/563 [============================>.] - ETA: 0s - loss: 0.6708 - categorical_accuracy: 0.5590WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.6705 - categorical_accuracy: 0.5604 - val_loss: 0.6470 - val_categorical_accuracy: 0.6140 - lr: 0.0010\n","Epoch 11/20\n","560/563 [============================>.] - ETA: 0s - loss: 0.6454 - categorical_accuracy: 0.6097WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.6453 - categorical_accuracy: 0.6099 - val_loss: 0.6240 - val_categorical_accuracy: 0.6408 - lr: 0.0010\n","Epoch 12/20\n","551/563 [============================>.] - ETA: 0s - loss: 0.6210 - categorical_accuracy: 0.6417WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.6209 - categorical_accuracy: 0.6415 - val_loss: 0.6190 - val_categorical_accuracy: 0.6448 - lr: 0.0010\n","Epoch 13/20\n","553/563 [============================>.] - ETA: 0s - loss: 0.6053 - categorical_accuracy: 0.6569WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.6052 - categorical_accuracy: 0.6572 - val_loss: 0.6108 - val_categorical_accuracy: 0.6492 - lr: 0.0010\n","Epoch 14/20\n","550/563 [============================>.] - ETA: 0s - loss: 0.5935 - categorical_accuracy: 0.6687WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 5ms/step - loss: 0.5931 - categorical_accuracy: 0.6692 - val_loss: 0.6098 - val_categorical_accuracy: 0.6488 - lr: 0.0010\n","Epoch 15/20\n","555/563 [============================>.] - ETA: 0s - loss: 0.5787 - categorical_accuracy: 0.6842WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.5789 - categorical_accuracy: 0.6840 - val_loss: 0.6033 - val_categorical_accuracy: 0.6548 - lr: 0.0010\n","Epoch 16/20\n","563/563 [==============================] - ETA: 0s - loss: 0.5673 - categorical_accuracy: 0.6918WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.5673 - categorical_accuracy: 0.6918 - val_loss: 0.6086 - val_categorical_accuracy: 0.6580 - lr: 0.0010\n","Epoch 17/20\n","559/563 [============================>.] - ETA: 0s - loss: 0.5514 - categorical_accuracy: 0.7080WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.5513 - categorical_accuracy: 0.7082 - val_loss: 0.6218 - val_categorical_accuracy: 0.6584 - lr: 0.0010\n","Epoch 18/20\n","559/563 [============================>.] - ETA: 0s - loss: 0.5351 - categorical_accuracy: 0.7183WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.5351 - categorical_accuracy: 0.7183 - val_loss: 0.6353 - val_categorical_accuracy: 0.6584 - lr: 0.0010\n","Epoch 19/20\n","556/563 [============================>.] - ETA: 0s - loss: 0.5189 - categorical_accuracy: 0.7299WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.5189 - categorical_accuracy: 0.7299 - val_loss: 0.6302 - val_categorical_accuracy: 0.6504 - lr: 0.0010\n","Epoch 20/20\n","555/563 [============================>.] - ETA: 0s - loss: 0.5006 - categorical_accuracy: 0.7430WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.5008 - categorical_accuracy: 0.7428 - val_loss: 0.6401 - val_categorical_accuracy: 0.6608 - lr: 0.0010\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3370461240>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"BTMmrjQvaDr7","colab_type":"code","outputId":"8399679a-3eea-46f0-adb3-eb200ddeb354","executionInfo":{"status":"ok","timestamp":1589134809694,"user_tz":-300,"elapsed":53543,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model4.fit(train_data,train_Labels, epochs=20, batch_size=32,verbose=1,shuffle=True,callbacks=callbacks_list,validation_data=(np.array(valid_data),np.array(valid_Labels)))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","561/563 [============================>.] - ETA: 0s - loss: 0.6930 - categorical_accuracy: 0.5127WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 5ms/step - loss: 0.6930 - categorical_accuracy: 0.5129 - val_loss: 0.6873 - val_categorical_accuracy: 0.5580 - lr: 0.0010\n","Epoch 2/20\n","557/563 [============================>.] - ETA: 0s - loss: 0.6675 - categorical_accuracy: 0.5836WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 5ms/step - loss: 0.6672 - categorical_accuracy: 0.5837 - val_loss: 0.6291 - val_categorical_accuracy: 0.6324 - lr: 0.0010\n","Epoch 3/20\n","562/563 [============================>.] - ETA: 0s - loss: 0.6285 - categorical_accuracy: 0.6339WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.6285 - categorical_accuracy: 0.6339 - val_loss: 0.6179 - val_categorical_accuracy: 0.6424 - lr: 0.0010\n","Epoch 4/20\n","563/563 [==============================] - ETA: 0s - loss: 0.6137 - categorical_accuracy: 0.6479WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.6137 - categorical_accuracy: 0.6479 - val_loss: 0.6031 - val_categorical_accuracy: 0.6556 - lr: 0.0010\n","Epoch 5/20\n","563/563 [==============================] - ETA: 0s - loss: 0.6043 - categorical_accuracy: 0.6577WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.6043 - categorical_accuracy: 0.6577 - val_loss: 0.6010 - val_categorical_accuracy: 0.6596 - lr: 0.0010\n","Epoch 6/20\n","554/563 [============================>.] - ETA: 0s - loss: 0.5915 - categorical_accuracy: 0.6696WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 5ms/step - loss: 0.5922 - categorical_accuracy: 0.6691 - val_loss: 0.5953 - val_categorical_accuracy: 0.6608 - lr: 0.0010\n","Epoch 7/20\n","552/563 [============================>.] - ETA: 0s - loss: 0.5850 - categorical_accuracy: 0.6762WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.5855 - categorical_accuracy: 0.6757 - val_loss: 0.5931 - val_categorical_accuracy: 0.6700 - lr: 0.0010\n","Epoch 8/20\n","556/563 [============================>.] - ETA: 0s - loss: 0.5699 - categorical_accuracy: 0.6908WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 5ms/step - loss: 0.5699 - categorical_accuracy: 0.6907 - val_loss: 0.5944 - val_categorical_accuracy: 0.6632 - lr: 0.0010\n","Epoch 9/20\n","553/563 [============================>.] - ETA: 0s - loss: 0.5605 - categorical_accuracy: 0.6972WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 2s 4ms/step - loss: 0.5609 - categorical_accuracy: 0.6967 - val_loss: 0.5969 - val_categorical_accuracy: 0.6720 - lr: 0.0010\n","Epoch 10/20\n","560/563 [============================>.] - ETA: 0s - loss: 0.5447 - categorical_accuracy: 0.7074WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.5446 - categorical_accuracy: 0.7071 - val_loss: 0.6056 - val_categorical_accuracy: 0.6692 - lr: 0.0010\n","Epoch 11/20\n","562/563 [============================>.] - ETA: 0s - loss: 0.5276 - categorical_accuracy: 0.7213WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.5275 - categorical_accuracy: 0.7213 - val_loss: 0.6027 - val_categorical_accuracy: 0.6736 - lr: 0.0010\n","Epoch 12/20\n","562/563 [============================>.] - ETA: 0s - loss: 0.5066 - categorical_accuracy: 0.7365WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 5ms/step - loss: 0.5067 - categorical_accuracy: 0.7366 - val_loss: 0.6531 - val_categorical_accuracy: 0.6604 - lr: 0.0010\n","Epoch 13/20\n","552/563 [============================>.] - ETA: 0s - loss: 0.4839 - categorical_accuracy: 0.7541WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.4838 - categorical_accuracy: 0.7547 - val_loss: 0.6372 - val_categorical_accuracy: 0.6540 - lr: 0.0010\n","Epoch 14/20\n","554/563 [============================>.] - ETA: 0s - loss: 0.4583 - categorical_accuracy: 0.7702WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 5ms/step - loss: 0.4585 - categorical_accuracy: 0.7704 - val_loss: 0.6759 - val_categorical_accuracy: 0.6516 - lr: 0.0010\n","Epoch 15/20\n","561/563 [============================>.] - ETA: 0s - loss: 0.4289 - categorical_accuracy: 0.7857WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.4290 - categorical_accuracy: 0.7857 - val_loss: 0.7044 - val_categorical_accuracy: 0.6576 - lr: 0.0010\n","Epoch 16/20\n","558/563 [============================>.] - ETA: 0s - loss: 0.4029 - categorical_accuracy: 0.8016WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 5ms/step - loss: 0.4023 - categorical_accuracy: 0.8023 - val_loss: 0.7581 - val_categorical_accuracy: 0.6520 - lr: 0.0010\n","Epoch 17/20\n","563/563 [==============================] - ETA: 0s - loss: 0.3710 - categorical_accuracy: 0.8172WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.3710 - categorical_accuracy: 0.8172 - val_loss: 0.7681 - val_categorical_accuracy: 0.6420 - lr: 0.0010\n","Epoch 18/20\n","552/563 [============================>.] - ETA: 0s - loss: 0.2882 - categorical_accuracy: 0.8658WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 5ms/step - loss: 0.2886 - categorical_accuracy: 0.8655 - val_loss: 0.9750 - val_categorical_accuracy: 0.6464 - lr: 2.0000e-04\n","Epoch 19/20\n","562/563 [============================>.] - ETA: 0s - loss: 0.2618 - categorical_accuracy: 0.8779WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.2619 - categorical_accuracy: 0.8779 - val_loss: 1.0704 - val_categorical_accuracy: 0.6480 - lr: 2.0000e-04\n","Epoch 20/20\n","559/563 [============================>.] - ETA: 0s - loss: 0.2438 - categorical_accuracy: 0.8858WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n","WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","563/563 [==============================] - 3s 4ms/step - loss: 0.2436 - categorical_accuracy: 0.8861 - val_loss: 1.2080 - val_categorical_accuracy: 0.6428 - lr: 2.0000e-04\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f331e232160>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"DChGxamqaYJs","colab_type":"text"},"source":["#**GRU**"]},{"cell_type":"code","metadata":{"id":"k_zCzinEaPM1","colab_type":"code","outputId":"c0f63e26-5a97-4123-8eb5-cbe4ae2aedfb","executionInfo":{"status":"ok","timestamp":1589134810323,"user_tz":-300,"elapsed":54155,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":436}},"source":["#predictions = code here\n","labelList=[\"Neg\",\"Pos\"]\n","predictions = model3.predict(test_data)\n","\n","pred=[]\n","for i in predictions:\n","    pred.append(np.argmax(i))\n","predictions=pred\n","\n","from sklearn.metrics import confusion_matrix\n","\n","test_Y_max=np.argmax(test_Labels, axis=-1)\n","cm=confusion_matrix(test_Y_max,predictions)\n","cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n","plt.figure(figsize=(10,7))\n","sn.set(font_scale=1.4) # for label size\n","sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n","plt.show()"],"execution_count":19,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x504 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"CANTvNR1a-Mw","colab_type":"code","outputId":"0f1b8cef-32a1-4158-f182-b40e7bdfc9af","executionInfo":{"status":"ok","timestamp":1589134810327,"user_tz":-300,"elapsed":54145,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = labelList))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Classification Report\n","               precision    recall  f1-score   support\n","\n","         Neg       0.66      0.66      0.66      2265\n","         Pos       0.65      0.66      0.66      2235\n","\n","    accuracy                           0.66      4500\n","   macro avg       0.66      0.66      0.66      4500\n","weighted avg       0.66      0.66      0.66      4500\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7IG0IwvjbLKs","colab_type":"text"},"source":["#**LSTM**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JTWCsexObQeT","outputId":"cef29d70-71af-4fa5-8eec-1f01a2cb755f","executionInfo":{"status":"ok","timestamp":1589134810998,"user_tz":-300,"elapsed":54805,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":436}},"source":["#predictions = code here\n","labelList=[\"Neg\",\"Pos\"]\n","predictions = model4.predict(test_data)\n","\n","pred=[]\n","for i in predictions:\n","    pred.append(np.argmax(i))\n","predictions=pred\n","\n","from sklearn.metrics import confusion_matrix\n","\n","test_Y_max=np.argmax(test_Labels, axis=-1)\n","cm=confusion_matrix(test_Y_max,predictions)\n","cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n","plt.figure(figsize=(10,7))\n","sn.set(font_scale=1.4) # for label size\n","sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n","plt.show()\n"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x504 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xMUG38zMbVpO","outputId":"97e338c6-489c-496f-a6d6-1641b82ee386","executionInfo":{"status":"ok","timestamp":1589134810999,"user_tz":-300,"elapsed":54773,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = labelList))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Classification Report\n","               precision    recall  f1-score   support\n","\n","         Neg       0.65      0.62      0.63      2265\n","         Pos       0.63      0.66      0.64      2235\n","\n","    accuracy                           0.64      4500\n","   macro avg       0.64      0.64      0.64      4500\n","weighted avg       0.64      0.64      0.64      4500\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xucfETSZgfu8","colab_type":"text"},"source":["# We hope all of you are working on your projects and <a href=\"https://ibb.co/dcpf4vS\"> Kudos for completing the assingnment</a>"]}]}