{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Ungraded.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Zdf8RYZd4zxT","colab_type":"text"},"source":["# Extra task\n","<b>This task is not graded, you are not required to submit this. This is just for your learning only attempt this if you have extra time</b>"]},{"cell_type":"markdown","metadata":{"id":"u7U-X50f4zxU","colab_type":"text"},"source":["# POS Tagging\n","\n","For this task we will be using the many to many archetecture(the first one from the left)\n","<img src=\"archetecturernn.png\">\n","This archtecture is called the encoder-decoder or the sequence 2 sequence(Seq2seq) model. For this task we will be using the brown [Brown Corpus](https://en.wikipedia.org/wiki/Brown_Corpus), you can import this from nltk.corpus.Here is a visual guide for how this will work:\n","![alt text](https://blog.keras.io/img/seq2seq/seq2seq-teacher-forcing.png)\n","This image ilustrates the task of translation from one language to another. We will instead use the same techniques for POS tagging.<br>\n","<b>How the mode works:</b> The model uses 2 LSTM's. The first LSTM encodes the sentence into feature vector of sorts and the second LSTM then uses this vector to predict a sequence of POS tags. After each prediction we will provide the actual tag instead of the predicted so that our model learns faster this technique is called <a href=\"https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c\">Teacher Forcing</a><br>\n","\n","\n","<h3>Data Preperation</h3>\n","<ul>\n","    <li> First we need to preprocess the data, convert the data to lower casing.</li>\n","    <li> Split the data into test, train and validation in the ratio 20,70,10. Use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">scikit_test_train_split</a> <br><i><b>Hint:</b> use the splitter twice to get desired data splits.</i></li>\n","    <li> For this task our model will have 2 inputs the sentence and the actual tag sequence. The labels/targets will also be the actual tag sequence.Inputs=(sentence,input tag sequence), Output=(output tag sequence)</li>\n","    <li> For the input tag sequence append start of sentence '[START]'or '[SOS] tag at start of the sentence and for prediction tag sequence append  end of sentence '[STOP]' or '[EOS]' tag. These tag help the model learn when to start and end a sequence of predictions</li>\n","    <li> Repeat the process of extracting vocabulary and numeric encoding for both the inputs and one hot encodings for prediction tag sequence.<li>\n","</ul>\n","<h3>Embeddings</h3>\n","<ul>\n","    <li>For this part instead of using pretrained embeddings you will use train them from scratch</li>\n","</ul>\n","<h3>Create Model</h3>\n","<ul>\n","    <li> Create the model using <a href\"https://www.tensorflow.org/guide/keras/functional\">functional API</a></li>\n","    <li> Hints: The emebedding layer has a parameter that allows you to use pretrained embeddings, for shared layers read the section of shared layer weights in function API docs</li>"]},{"cell_type":"code","metadata":{"id":"6XPFEZ5j453F","colab_type":"code","outputId":"a8ad0f27-8386-40dc-8bb0-ed48bc9fef42","executionInfo":{"status":"ok","timestamp":1589128818541,"user_tz":-300,"elapsed":5257,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}},"colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["%matplotlib inline\n","import numpy as np\n","from IPython.display import Image\n","# Get the interactive Tools for Matplotlib\n","import matplotlib.pyplot as plt\n","plt.style.use('ggplot')\n","from sklearn.decomposition import PCA\n","from gensim.test.utils import datapath, get_tmpfile\n","from gensim.models import KeyedVectors\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.utils.extmath import randomized_svd\n","from nltk import ngrams\n","import pandas as pd\n","import seaborn as sn\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Activation, RepeatVector,Flatten, TimeDistributed, Input,Bidirectional,LocallyConnected1D,Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n","from tensorflow.keras.layers import Embedding, LSTM ,Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import optimizers\n","# from tensorflow.keras.utils.vis_utils import plot_model\n","from tensorflow.keras.utils import to_categorical\n","# import tensorflow.keras.utils.to_categorical as to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","import matplotlib.pyplot as plt\n","import matplotlib.mlab as mlab\n","from sklearn.model_selection import train_test_split as splitter\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n","from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n","import math\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sn\n","from sklearn.metrics import classification_report\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","nltk.download('brown')\n","from nltk.corpus import brown\n","from gensim.models import Word2Vec"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EvNJGSrP4zxd","colab_type":"code","colab":{}},"source":["def preprocessing(data):\n","  sentences = []\n","  sen=[]\n","  for i in data:\n","    for j in i:\n","      z=re.match('[a-zA-Z\\-]+',j)\n","      if z:\n","        j=j.lower()\n","      sen.append(j)\n","    sentences.append(sen)\n","    sen=[]\n","  return sentences\n","\n","data = preprocessing(brown.sents())\n","tags = list(brown.tagged_sents())\n","\n","for i in range(0,len(tags)):\n","  tags[i]=[j[1] for j in tags[i]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"McbCdMM2fwmR","colab_type":"code","colab":{}},"source":["#SOS EOS\n","tags2=[] \n","for i in tags:\n","  tags2.append( ['SOS'] + i + ['EOS'])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-U8rXijsnAa","colab_type":"code","colab":{}},"source":["tokenizer2=Tokenizer()\n","tokenizer2.fit_on_texts(tags2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ve_P4w798zbz","colab_type":"code","colab":{}},"source":["def testTrainSplit(data_X,data_Y):\n","\n","    train_data,valid_data,train_labels,valid_labels=splitter(data_X,data_Y,train_size=0.9,test_size=0.1,shuffle=True)\n","    train_data,test_data,train_labels,test_labels=splitter(train_data,train_labels,train_size=0.8,test_size=0.2,shuffle=True)\n","\n","    return train_data,train_labels,test_data,test_labels,valid_data,valid_labels\n","\n","train_data,train_labels,test_data,test_labels,valid_data,valid_labels=testTrainSplit(data,tags)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0lPFBI--sK8p","colab_type":"code","colab":{}},"source":["tokenizer1=Tokenizer(split=' ',oov_token=\"UNK\")\n","tokenizer.fit_on_texts(train_data)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sfgYgWT8giKZ","colab_type":"code","colab":{}},"source":["#generating \n","train_vocab = list(tokenizer.word_index.keys())\n","tag_vocab = list(tokenizer2.word_index.keys())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"97hrrLo1gSTF","colab_type":"code","colab":{}},"source":["def label_seq(data):\n","  decoder_in_seq=[]\n","  decoder_out_seq=[]\n","  for i in data:\n","    decoder_in_seq.append(['SOS'] + i)\n","  for i in data:\n","    decoder_out_seq.append(i + ['EOS'])\n","  return decoder_in_seq,decoder_out_seq\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3kTfBuJZvfvf","colab_type":"code","colab":{}},"source":["train_decoder_in,train_decoder_out=label_seq(train_labels)\n","test_decoder_in,test_decoder_out=label_seq(test_data)\n","valid_decoder_in,valid_decoder_out=label_seq(valid_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2meuMlvNt25B","colab_type":"code","colab":{}},"source":["def text2seq(tokenizer,data):\n","  seq = tokenizer.texts_to_sequences(data)\n","  seq=pad_sequences(seq,padding=\"post\",maxlen=15)\n","  return seq\n","\n","train_seq=text2seq(tokenizer,train_data)\n","test_seq=text2seq(tokenizer,test_data)\n","valid_seq=text2seq(tokenizer,valid_data)\n","\n","train_decoder_in=text2seq(tokenizer2,train_decoder_in)\n","test_decoder_in=text2seq(tokenizer2,test_decoder_in)\n","valid_decoder_in=text2seq(tokenizer2,valid_decoder_in)\n","\n","train_decoder_out=text2seq(tokenizer2,train_decoder_out)\n","test_decoder_out=text2seq(tokenizer2,test_decoder_out)\n","valid_decoder_out=text2seq(tokenizer2,valid_decoder_out)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lAR4dY2A1LuZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"1cc7e234-8b4f-4bfa-8fe5-ce2709096f9e","executionInfo":{"status":"ok","timestamp":1589135128520,"user_tz":-300,"elapsed":1121,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}}},"source":["train_decoder_in[0]"],"execution_count":131,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([19,  4,  1, 10, 19,  4,  1, 21, 11, 15,  3,  4, 18,  1,  5],\n","      dtype=int32)"]},"metadata":{"tags":[]},"execution_count":131}]},{"cell_type":"code","metadata":{"id":"9cU4IXBtUpd_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":494},"outputId":"711e94b3-9843-4818-8b1d-76482bbda589","executionInfo":{"status":"ok","timestamp":1589135131577,"user_tz":-300,"elapsed":1119,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}}},"source":["#model \n","encoder_inputs = Input(shape=(15,))\n","emb1 = Embedding(len(train_vocab),100,input_length=15,trainable=True)(encoder_inputs)\n","lstm_encoder, state_h, state_c=LSTM(100, return_sequences=True, return_state=True,recurrent_dropout=0.2)(emb1)#apply bidirectional lstm\n","encoder_states = [state_h, state_c]\n","decoder_inputs = Input(shape=(15,))\n","emb2 = Embedding(len(tag_vocab),100,input_length=15,trainable=True)(decoder_inputs)\n","lstm_decoder,_,_= LSTM(100,return_sequences=True, return_state=True,recurrent_dropout=0.2)(emb2,initial_state=[state_h, state_c])#apply bidirectional lstm\n","decoder_dense = Dense(len(tag_vocab), activation='softmax')(lstm_decoder)\n","\n","model = Model(inputs=[encoder_inputs,decoder_inputs], outputs=[decoder_dense])\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_crossentropy'])\n","model.summary()\n"],"execution_count":132,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_11 (InputLayer)           [(None, 15)]         0                                            \n","__________________________________________________________________________________________________\n","input_12 (InputLayer)           [(None, 15)]         0                                            \n","__________________________________________________________________________________________________\n","embedding_10 (Embedding)        (None, 15, 100)      4981600     input_11[0][0]                   \n","__________________________________________________________________________________________________\n","embedding_11 (Embedding)        (None, 15, 100)      47400       input_12[0][0]                   \n","__________________________________________________________________________________________________\n","lstm_10 (LSTM)                  [(None, 15, 100), (N 80400       embedding_10[0][0]               \n","__________________________________________________________________________________________________\n","lstm_11 (LSTM)                  [(None, 15, 100), (N 80400       embedding_11[0][0]               \n","                                                                 lstm_10[0][1]                    \n","                                                                 lstm_10[0][2]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 15, 474)      47874       lstm_11[0][0]                    \n","==================================================================================================\n","Total params: 5,237,674\n","Trainable params: 5,237,674\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tWY8KW1R0yIq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":336},"outputId":"b9070a43-f3dc-4fd9-baa9-c9abd806b58d","executionInfo":{"status":"error","timestamp":1589135140184,"user_tz":-300,"elapsed":5434,"user":{"displayName":"Muhammad Sameer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmNptdWMb_my5huqiQN2IjhtioUZbnSCVUDUoE5w=s64","userId":"17564536614325976306"}}},"source":["model.fit([np.array(train_seq),np.array(train_decoder_in)],train_labels, epochs=20, batch_size=32,verbose=1,shuffle=True)"],"execution_count":133,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-133-47aff1932f81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_decoder_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    813\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 963\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    964\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     raise RuntimeError(\n","\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'str\\'>\"})'})"]}]}]}